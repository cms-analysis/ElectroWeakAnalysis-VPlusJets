[CRAB]

jobtype = cmssw
scheduler = condor


[CMSSW]

### The data you want to access (to be found on DBS) 
datasetpath=mydataset


### The ParameterSet you want to use
pset = myanalysis


#
get_edm_output = 1


### Splitting parameters
#total_number_of_events=-1
#events_per_job = 200000
#number_of_jobs = 1
total_number_of_lumis=-1
lumis_per_job = 100


[USER]
##################################################
### CHANGE THIS
ui_working_dir = crabDirmyworkingdir
### CHANGE THIS if you are running on data or are making a new version
publish_data_name = SQWaT_PAT_42X_mypublishname
##################################################

### OUTPUT files Management
##  output back into UI 
return_data = 0


### OUTPUT files INTO A SE
copy_data = 1
storage_element = cmssrm.fnal.gov
publish_data = 1
check_user_remote_dir = 0
dbs_url_for_publication = https://cmsdbsprod.cern.ch:8443/cms_dbs_ph_analysis_02_writer/servlet/DBSServlet

#storage_path = /srm/managerv2?SFN=/resilient
storage_path = /srm/managerv2?SFN=/11
user_remote_dir = myresilient

[SQWaT]

### CHANGE THIS to False for data
runOnMC = False
useTrigger = False
triggerSelection = HLT_IsoMu17_v*
### CHANGE THIS to True for samples used in trigger/ID SF studies
keepSuperClusters = False

[GRID]

## RB/WMS management:
rb = CERN


## CMS myproxy server, to proxy delegation
proxy_server = myproxy.cern.ch


